// Code generated by user config generator. DO NOT EDIT.

package kafkaconnect

import (
	"context"

	setvalidator "github.com/hashicorp/terraform-plugin-framework-validators/setvalidator"
	attr "github.com/hashicorp/terraform-plugin-framework/attr"
	datasource "github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	diag "github.com/hashicorp/terraform-plugin-framework/diag"
	resource "github.com/hashicorp/terraform-plugin-framework/resource/schema"
	validator "github.com/hashicorp/terraform-plugin-framework/schema/validator"
	types "github.com/hashicorp/terraform-plugin-framework/types"

	schemautil "github.com/aiven/terraform-provider-aiven/internal/schemautil"
)

// NewResourceSchema returns resource schema
func NewResourceSchema() resource.SetNestedBlock {
	return resource.SetNestedBlock{
		Description: "Integration user config",
		NestedObject: resource.NestedBlockObject{Blocks: map[string]resource.Block{"kafka_connect": resource.SetNestedBlock{
			Description: "Kafka Connect service configuration values",
			NestedObject: resource.NestedBlockObject{Attributes: map[string]resource.Attribute{
				"config_storage_topic": resource.StringAttribute{
					Computed:    true,
					Description: "The name of the topic where connector and task configuration data are stored.This must be the same for all workers with the same group_id.",
					Optional:    true,
				},
				"group_id": resource.StringAttribute{
					Computed:    true,
					Description: "A unique string that identifies the Connect cluster group this worker belongs to.",
					Optional:    true,
				},
				"offset_storage_topic": resource.StringAttribute{
					Computed:    true,
					Description: "The name of the topic where connector and task configuration offsets are stored.This must be the same for all workers with the same group_id.",
					Optional:    true,
				},
				"status_storage_topic": resource.StringAttribute{
					Computed:    true,
					Description: "The name of the topic where connector and task configuration status updates are stored.This must be the same for all workers with the same group_id.",
					Optional:    true,
				},
			}},
		}}},
		Validators: []validator.Set{setvalidator.SizeAtMost(1)},
	}
}

// NewDataSourceSchema returns datasource schema
func NewDataSourceSchema() datasource.SetNestedBlock {
	return datasource.SetNestedBlock{
		Description: "Integration user config",
		NestedObject: datasource.NestedBlockObject{Blocks: map[string]datasource.Block{"kafka_connect": datasource.SetNestedBlock{
			Description: "Kafka Connect service configuration values",
			NestedObject: datasource.NestedBlockObject{Attributes: map[string]datasource.Attribute{
				"config_storage_topic": datasource.StringAttribute{
					Computed:    true,
					Description: "The name of the topic where connector and task configuration data are stored.This must be the same for all workers with the same group_id.",
				},
				"group_id": datasource.StringAttribute{
					Computed:    true,
					Description: "A unique string that identifies the Connect cluster group this worker belongs to.",
				},
				"offset_storage_topic": datasource.StringAttribute{
					Computed:    true,
					Description: "The name of the topic where connector and task configuration offsets are stored.This must be the same for all workers with the same group_id.",
				},
				"status_storage_topic": datasource.StringAttribute{
					Computed:    true,
					Description: "The name of the topic where connector and task configuration status updates are stored.This must be the same for all workers with the same group_id.",
				},
			}},
		}}},
		Validators: []validator.Set{setvalidator.SizeAtMost(1)},
	}
}

// tfoUserConfig Integration user config
type tfoUserConfig struct {
	KafkaConnect types.Set `tfsdk:"kafka_connect"`
}

// dtoUserConfig request/response object
type dtoUserConfig struct {
	KafkaConnect *dtoKafkaConnect `groups:"create,update" json:"kafka_connect,omitempty"`
}

// expandUserConfig expands tf object into dto object
func expandUserConfig(ctx context.Context, diags *diag.Diagnostics, o *tfoUserConfig) *dtoUserConfig {
	kafkaConnectVar := schemautil.ExpandSetBlockNested[tfoKafkaConnect, dtoKafkaConnect](ctx, diags, expandKafkaConnect, o.KafkaConnect)
	if diags.HasError() {
		return nil
	}
	return &dtoUserConfig{KafkaConnect: kafkaConnectVar}
}

// flattenUserConfig flattens dto object into tf object
func flattenUserConfig(ctx context.Context, diags *diag.Diagnostics, o *dtoUserConfig) *tfoUserConfig {
	kafkaConnectVar := schemautil.FlattenSetBlockNested[dtoKafkaConnect, tfoKafkaConnect](ctx, diags, flattenKafkaConnect, kafkaConnectAttrs, o.KafkaConnect)
	if diags.HasError() {
		return nil
	}
	return &tfoUserConfig{KafkaConnect: kafkaConnectVar}
}

var userConfigAttrs = map[string]attr.Type{"kafka_connect": types.SetType{ElemType: types.ObjectType{AttrTypes: kafkaConnectAttrs}}}

// tfoKafkaConnect Kafka Connect service configuration values
type tfoKafkaConnect struct {
	ConfigStorageTopic types.String `tfsdk:"config_storage_topic"`
	GroupId            types.String `tfsdk:"group_id"`
	OffsetStorageTopic types.String `tfsdk:"offset_storage_topic"`
	StatusStorageTopic types.String `tfsdk:"status_storage_topic"`
}

// dtoKafkaConnect request/response object
type dtoKafkaConnect struct {
	ConfigStorageTopic *string `groups:"create,update" json:"config_storage_topic,omitempty"`
	GroupId            *string `groups:"create,update" json:"group_id,omitempty"`
	OffsetStorageTopic *string `groups:"create,update" json:"offset_storage_topic,omitempty"`
	StatusStorageTopic *string `groups:"create,update" json:"status_storage_topic,omitempty"`
}

// expandKafkaConnect expands tf object into dto object
func expandKafkaConnect(ctx context.Context, diags *diag.Diagnostics, o *tfoKafkaConnect) *dtoKafkaConnect {
	return &dtoKafkaConnect{
		ConfigStorageTopic: schemautil.ValueStringPointer(o.ConfigStorageTopic),
		GroupId:            schemautil.ValueStringPointer(o.GroupId),
		OffsetStorageTopic: schemautil.ValueStringPointer(o.OffsetStorageTopic),
		StatusStorageTopic: schemautil.ValueStringPointer(o.StatusStorageTopic),
	}
}

// flattenKafkaConnect flattens dto object into tf object
func flattenKafkaConnect(ctx context.Context, diags *diag.Diagnostics, o *dtoKafkaConnect) *tfoKafkaConnect {
	return &tfoKafkaConnect{
		ConfigStorageTopic: types.StringPointerValue(o.ConfigStorageTopic),
		GroupId:            types.StringPointerValue(o.GroupId),
		OffsetStorageTopic: types.StringPointerValue(o.OffsetStorageTopic),
		StatusStorageTopic: types.StringPointerValue(o.StatusStorageTopic),
	}
}

var kafkaConnectAttrs = map[string]attr.Type{
	"config_storage_topic": types.StringType,
	"group_id":             types.StringType,
	"offset_storage_topic": types.StringType,
	"status_storage_topic": types.StringType,
}

// Expand public function that converts tf object into dto
func Expand(ctx context.Context, diags *diag.Diagnostics, set types.Set) *dtoUserConfig {
	return schemautil.ExpandSetBlockNested[tfoUserConfig, dtoUserConfig](ctx, diags, expandUserConfig, set)
}

// Flatten public function that converts dto into tf object
func Flatten(ctx context.Context, diags *diag.Diagnostics, m map[string]any) types.Set {
	o := new(dtoUserConfig)
	err := schemautil.MapToDTO(m, o)
	if err != nil {
		diags.AddError("failed to marshal map user config to dto", err.Error())
		return types.SetNull(types.ObjectType{AttrTypes: userConfigAttrs})
	}
	return schemautil.FlattenSetBlockNested[dtoUserConfig, tfoUserConfig](ctx, diags, flattenUserConfig, userConfigAttrs, o)
}
