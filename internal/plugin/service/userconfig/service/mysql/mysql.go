// Code generated by user config generator. DO NOT EDIT.

package mysql

import (
	"context"
	"encoding/json"

	setvalidator "github.com/hashicorp/terraform-plugin-framework-validators/setvalidator"
	attr "github.com/hashicorp/terraform-plugin-framework/attr"
	datasource "github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	diag "github.com/hashicorp/terraform-plugin-framework/diag"
	resource "github.com/hashicorp/terraform-plugin-framework/resource/schema"
	booldefault "github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault"
	validator "github.com/hashicorp/terraform-plugin-framework/schema/validator"
	types "github.com/hashicorp/terraform-plugin-framework/types"

	schemautil "github.com/aiven/terraform-provider-aiven/internal/schemautil"
)

// NewResourceSchema returns resource schema
func NewResourceSchema() resource.SetNestedBlock {
	return resource.SetNestedBlock{
		Description: "Mysql user configurable settings",
		NestedObject: resource.NestedBlockObject{
			Attributes: map[string]resource.Attribute{
				"additional_backup_regions": resource.SetAttribute{
					Computed:    true,
					Description: "Additional Cloud Regions for Backup Replication.",
					ElementType: types.StringType,
					Optional:    true,
					Validators:  []validator.Set{setvalidator.SizeAtMost(1)},
				},
				"admin_password": resource.StringAttribute{
					Computed:    true,
					Description: "Custom password for admin user. Defaults to random string. This must be set only when a new service is being created.",
					Optional:    true,
				},
				"admin_username": resource.StringAttribute{
					Computed:    true,
					Description: "Custom username for admin user. This must be set only when a new service is being created.",
					Optional:    true,
				},
				"backup_hour": resource.Int64Attribute{
					Computed:    true,
					Description: "The hour of day (in UTC) when backup for the service is started. New backup is only started if previous backup has already completed.",
					Optional:    true,
				},
				"backup_minute": resource.Int64Attribute{
					Computed:    true,
					Description: "The minute of an hour when backup for the service is started. New backup is only started if previous backup has already completed.",
					Optional:    true,
				},
				"binlog_retention_period": resource.Int64Attribute{
					Computed:    true,
					Description: "The minimum amount of time in seconds to keep binlog entries before deletion. This may be extended for services that require binlog entries for longer than the default for example if using the MySQL Debezium Kafka connector.",
					Optional:    true,
				},
				"mysql_version": resource.StringAttribute{
					Computed:    true,
					Description: "MySQL major version.",
					Optional:    true,
				},
				"project_to_fork_from": resource.StringAttribute{
					Computed:    true,
					Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
					Optional:    true,
				},
				"recovery_target_time": resource.StringAttribute{
					Computed:    true,
					Description: "Recovery target time when forking a service. This has effect only when a new service is being created.",
					Optional:    true,
				},
				"service_to_fork_from": resource.StringAttribute{
					Computed:    true,
					Description: "Name of another service to fork from. This has effect only when a new service is being created.",
					Optional:    true,
				},
				"static_ips": resource.BoolAttribute{
					Computed:    true,
					Description: "Use static public IP addresses.",
					Optional:    true,
				},
			},
			Blocks: map[string]resource.Block{
				"ip_filter": resource.SetNestedBlock{
					Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
					NestedObject: resource.NestedBlockObject{Attributes: map[string]resource.Attribute{
						"description": resource.StringAttribute{
							Computed:    true,
							Description: "Description for IP filter list entry.",
							Optional:    true,
						},
						"network": resource.StringAttribute{
							Description: "CIDR address block.",
							Required:    true,
						},
					}},
					Validators: []validator.Set{setvalidator.SizeAtMost(1024)},
				},
				"migration": resource.SetNestedBlock{
					Description: "Migrate data from existing server",
					NestedObject: resource.NestedBlockObject{Attributes: map[string]resource.Attribute{
						"dbname": resource.StringAttribute{
							Computed:    true,
							Description: "Database name for bootstrapping the initial connection.",
							Optional:    true,
						},
						"host": resource.StringAttribute{
							Description: "Hostname or IP address of the server where to migrate data from.",
							Required:    true,
						},
						"ignore_dbs": resource.StringAttribute{
							Computed:    true,
							Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL and PostgreSQL only at the moment).",
							Optional:    true,
						},
						"method": resource.StringAttribute{
							Computed:    true,
							Description: "The migration method to be used (currently supported only by Redis, MySQL and PostgreSQL service types).",
							Optional:    true,
						},
						"password": resource.StringAttribute{
							Computed:    true,
							Description: "Password for authentication with the server where to migrate data from.",
							Optional:    true,
						},
						"port": resource.Int64Attribute{
							Description: "Port number of the server where to migrate data from.",
							Required:    true,
						},
						"ssl": resource.BoolAttribute{
							Computed:    true,
							Default:     booldefault.StaticBool(true),
							Description: "The server where to migrate data from is secured with SSL. The default value is `true`.",
							Optional:    true,
						},
						"username": resource.StringAttribute{
							Computed:    true,
							Description: "User name for authentication with the server where to migrate data from.",
							Optional:    true,
						},
					}},
				},
				"mysql": resource.SetNestedBlock{
					Description: "mysql.conf configuration values",
					NestedObject: resource.NestedBlockObject{Attributes: map[string]resource.Attribute{
						"connect_timeout": resource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds that the mysqld server waits for a connect packet before responding with Bad handshake.",
							Optional:    true,
						},
						"default_time_zone": resource.StringAttribute{
							Computed:    true,
							Description: "Default server time zone as an offset from UTC (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.",
							Optional:    true,
						},
						"group_concat_max_len": resource.Int64Attribute{
							Computed:    true,
							Description: "The maximum permitted result length in bytes for the GROUP_CONCAT() function.",
							Optional:    true,
						},
						"information_schema_stats_expiry": resource.Int64Attribute{
							Computed:    true,
							Description: "The time, in seconds, before cached statistics expire.",
							Optional:    true,
						},
						"innodb_change_buffer_max_size": resource.Int64Attribute{
							Computed:    true,
							Description: "Maximum size for the InnoDB change buffer, as a percentage of the total size of the buffer pool. Default is 25.",
							Optional:    true,
						},
						"innodb_flush_neighbors": resource.Int64Attribute{
							Computed:    true,
							Description: "Specifies whether flushing a page from the InnoDB buffer pool also flushes other dirty pages in the same extent (default is 1): 0 - dirty pages in the same extent are not flushed,  1 - flush contiguous dirty pages in the same extent,  2 - flush dirty pages in the same extent.",
							Optional:    true,
						},
						"innodb_ft_min_token_size": resource.Int64Attribute{
							Computed:    true,
							Description: "Minimum length of words that are stored in an InnoDB FULLTEXT index. Changing this parameter will lead to a restart of the MySQL service.",
							Optional:    true,
						},
						"innodb_ft_server_stopword_table": resource.StringAttribute{
							Computed:    true,
							Description: "This option is used to specify your own InnoDB FULLTEXT index stopword list for all InnoDB tables.",
							Optional:    true,
						},
						"innodb_lock_wait_timeout": resource.Int64Attribute{
							Computed:    true,
							Description: "The length of time in seconds an InnoDB transaction waits for a row lock before giving up. Default is 120.",
							Optional:    true,
						},
						"innodb_log_buffer_size": resource.Int64Attribute{
							Computed:    true,
							Description: "The size in bytes of the buffer that InnoDB uses to write to the log files on disk.",
							Optional:    true,
						},
						"innodb_online_alter_log_max_size": resource.Int64Attribute{
							Computed:    true,
							Description: "The upper limit in bytes on the size of the temporary log files used during online DDL operations for InnoDB tables.",
							Optional:    true,
						},
						"innodb_print_all_deadlocks": resource.BoolAttribute{
							Computed:    true,
							Description: "When enabled, information about all deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.",
							Optional:    true,
						},
						"innodb_read_io_threads": resource.Int64Attribute{
							Computed:    true,
							Description: "The number of I/O threads for read operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
							Optional:    true,
						},
						"innodb_rollback_on_timeout": resource.BoolAttribute{
							Computed:    true,
							Description: "When enabled a transaction timeout causes InnoDB to abort and roll back the entire transaction. Changing this parameter will lead to a restart of the MySQL service.",
							Optional:    true,
						},
						"innodb_thread_concurrency": resource.Int64Attribute{
							Computed:    true,
							Description: "Defines the maximum number of threads permitted inside of InnoDB. Default is 0 (infinite concurrency - no limit).",
							Optional:    true,
						},
						"innodb_write_io_threads": resource.Int64Attribute{
							Computed:    true,
							Description: "The number of I/O threads for write operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
							Optional:    true,
						},
						"interactive_timeout": resource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds the server waits for activity on an interactive connection before closing it.",
							Optional:    true,
						},
						"internal_tmp_mem_storage_engine": resource.StringAttribute{
							Computed:    true,
							Description: "The storage engine for in-memory internal temporary tables.",
							Optional:    true,
						},
						"long_query_time": resource.Float64Attribute{
							Computed:    true,
							Description: "The slow_query_logs work as SQL statements that take more than long_query_time seconds to execute. Default is 10s.",
							Optional:    true,
						},
						"max_allowed_packet": resource.Int64Attribute{
							Computed:    true,
							Description: "Size of the largest message in bytes that can be received by the server. Default is 67108864 (64M).",
							Optional:    true,
						},
						"max_heap_table_size": resource.Int64Attribute{
							Computed:    true,
							Description: "Limits the size of internal in-memory tables. Also set tmp_table_size. Default is 16777216 (16M).",
							Optional:    true,
						},
						"net_buffer_length": resource.Int64Attribute{
							Computed:    true,
							Description: "Start sizes of connection buffer and result buffer. Default is 16384 (16K). Changing this parameter will lead to a restart of the MySQL service.",
							Optional:    true,
						},
						"net_read_timeout": resource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds to wait for more data from a connection before aborting the read.",
							Optional:    true,
						},
						"net_write_timeout": resource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds to wait for a block to be written to a connection before aborting the write.",
							Optional:    true,
						},
						"slow_query_log": resource.BoolAttribute{
							Computed:    true,
							Description: "Slow query log enables capturing of slow queries. Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off.",
							Optional:    true,
						},
						"sort_buffer_size": resource.Int64Attribute{
							Computed:    true,
							Description: "Sort buffer size in bytes for ORDER BY optimization. Default is 262144 (256K).",
							Optional:    true,
						},
						"sql_mode": resource.StringAttribute{
							Computed:    true,
							Description: "Global SQL mode. Set to empty to use MySQL server defaults. When creating a new service and not setting this field Aiven default SQL mode (strict, SQL standard compliant) will be assigned.",
							Optional:    true,
						},
						"sql_require_primary_key": resource.BoolAttribute{
							Computed:    true,
							Description: "Require primary key to be defined for new tables or old tables modified with ALTER TABLE and fail if missing. It is recommended to always have primary keys because various functionality may break if any large table is missing them.",
							Optional:    true,
						},
						"tmp_table_size": resource.Int64Attribute{
							Computed:    true,
							Description: "Limits the size of internal in-memory tables. Also set max_heap_table_size. Default is 16777216 (16M).",
							Optional:    true,
						},
						"wait_timeout": resource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds the server waits for activity on a noninteractive connection before closing it.",
							Optional:    true,
						},
					}},
				},
				"private_access": resource.SetNestedBlock{
					Description: "Allow access to selected service ports from private networks",
					NestedObject: resource.NestedBlockObject{Attributes: map[string]resource.Attribute{
						"mysql": resource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysql with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations.",
							Optional:    true,
						},
						"mysqlx": resource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysqlx with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations.",
							Optional:    true,
						},
						"prometheus": resource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations.",
							Optional:    true,
						},
					}},
				},
				"privatelink_access": resource.SetNestedBlock{
					Description: "Allow access to selected service components through Privatelink",
					NestedObject: resource.NestedBlockObject{Attributes: map[string]resource.Attribute{
						"mysql": resource.BoolAttribute{
							Computed:    true,
							Description: "Enable mysql.",
							Optional:    true,
						},
						"mysqlx": resource.BoolAttribute{
							Computed:    true,
							Description: "Enable mysqlx.",
							Optional:    true,
						},
						"prometheus": resource.BoolAttribute{
							Computed:    true,
							Description: "Enable prometheus.",
							Optional:    true,
						},
					}},
				},
				"public_access": resource.SetNestedBlock{
					Description: "Allow access to selected service ports from the public Internet",
					NestedObject: resource.NestedBlockObject{Attributes: map[string]resource.Attribute{
						"mysql": resource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysql from the public internet for service nodes that are in a project VPC or another type of private network.",
							Optional:    true,
						},
						"mysqlx": resource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysqlx from the public internet for service nodes that are in a project VPC or another type of private network.",
							Optional:    true,
						},
						"prometheus": resource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network.",
							Optional:    true,
						},
					}},
				},
			},
		},
		Validators: []validator.Set{setvalidator.SizeAtMost(1)},
	}
}

// NewDataSourceSchema returns datasource schema
func NewDataSourceSchema() datasource.SetNestedBlock {
	return datasource.SetNestedBlock{
		Description: "Mysql user configurable settings",
		NestedObject: datasource.NestedBlockObject{
			Attributes: map[string]datasource.Attribute{
				"additional_backup_regions": datasource.SetAttribute{
					Computed:    true,
					Description: "Additional Cloud Regions for Backup Replication.",
					ElementType: types.StringType,
					Validators:  []validator.Set{setvalidator.SizeAtMost(1)},
				},
				"admin_password": datasource.StringAttribute{
					Computed:    true,
					Description: "Custom password for admin user. Defaults to random string. This must be set only when a new service is being created.",
				},
				"admin_username": datasource.StringAttribute{
					Computed:    true,
					Description: "Custom username for admin user. This must be set only when a new service is being created.",
				},
				"backup_hour": datasource.Int64Attribute{
					Computed:    true,
					Description: "The hour of day (in UTC) when backup for the service is started. New backup is only started if previous backup has already completed.",
				},
				"backup_minute": datasource.Int64Attribute{
					Computed:    true,
					Description: "The minute of an hour when backup for the service is started. New backup is only started if previous backup has already completed.",
				},
				"binlog_retention_period": datasource.Int64Attribute{
					Computed:    true,
					Description: "The minimum amount of time in seconds to keep binlog entries before deletion. This may be extended for services that require binlog entries for longer than the default for example if using the MySQL Debezium Kafka connector.",
				},
				"mysql_version": datasource.StringAttribute{
					Computed:    true,
					Description: "MySQL major version.",
				},
				"project_to_fork_from": datasource.StringAttribute{
					Computed:    true,
					Description: "Name of another project to fork a service from. This has effect only when a new service is being created.",
				},
				"recovery_target_time": datasource.StringAttribute{
					Computed:    true,
					Description: "Recovery target time when forking a service. This has effect only when a new service is being created.",
				},
				"service_to_fork_from": datasource.StringAttribute{
					Computed:    true,
					Description: "Name of another service to fork from. This has effect only when a new service is being created.",
				},
				"static_ips": datasource.BoolAttribute{
					Computed:    true,
					Description: "Use static public IP addresses.",
				},
			},
			Blocks: map[string]datasource.Block{
				"ip_filter": datasource.SetNestedBlock{
					Description: "Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'",
					NestedObject: datasource.NestedBlockObject{Attributes: map[string]datasource.Attribute{
						"description": datasource.StringAttribute{
							Computed:    true,
							Description: "Description for IP filter list entry.",
						},
						"network": datasource.StringAttribute{
							Computed:    true,
							Description: "CIDR address block.",
						},
					}},
					Validators: []validator.Set{setvalidator.SizeAtMost(1024)},
				},
				"migration": datasource.SetNestedBlock{
					Description: "Migrate data from existing server",
					NestedObject: datasource.NestedBlockObject{Attributes: map[string]datasource.Attribute{
						"dbname": datasource.StringAttribute{
							Computed:    true,
							Description: "Database name for bootstrapping the initial connection.",
						},
						"host": datasource.StringAttribute{
							Computed:    true,
							Description: "Hostname or IP address of the server where to migrate data from.",
						},
						"ignore_dbs": datasource.StringAttribute{
							Computed:    true,
							Description: "Comma-separated list of databases, which should be ignored during migration (supported by MySQL and PostgreSQL only at the moment).",
						},
						"method": datasource.StringAttribute{
							Computed:    true,
							Description: "The migration method to be used (currently supported only by Redis, MySQL and PostgreSQL service types).",
						},
						"password": datasource.StringAttribute{
							Computed:    true,
							Description: "Password for authentication with the server where to migrate data from.",
						},
						"port": datasource.Int64Attribute{
							Computed:    true,
							Description: "Port number of the server where to migrate data from.",
						},
						"ssl": datasource.BoolAttribute{
							Computed:    true,
							Description: "The server where to migrate data from is secured with SSL. The default value is `true`.",
						},
						"username": datasource.StringAttribute{
							Computed:    true,
							Description: "User name for authentication with the server where to migrate data from.",
						},
					}},
				},
				"mysql": datasource.SetNestedBlock{
					Description: "mysql.conf configuration values",
					NestedObject: datasource.NestedBlockObject{Attributes: map[string]datasource.Attribute{
						"connect_timeout": datasource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds that the mysqld server waits for a connect packet before responding with Bad handshake.",
						},
						"default_time_zone": datasource.StringAttribute{
							Computed:    true,
							Description: "Default server time zone as an offset from UTC (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.",
						},
						"group_concat_max_len": datasource.Int64Attribute{
							Computed:    true,
							Description: "The maximum permitted result length in bytes for the GROUP_CONCAT() function.",
						},
						"information_schema_stats_expiry": datasource.Int64Attribute{
							Computed:    true,
							Description: "The time, in seconds, before cached statistics expire.",
						},
						"innodb_change_buffer_max_size": datasource.Int64Attribute{
							Computed:    true,
							Description: "Maximum size for the InnoDB change buffer, as a percentage of the total size of the buffer pool. Default is 25.",
						},
						"innodb_flush_neighbors": datasource.Int64Attribute{
							Computed:    true,
							Description: "Specifies whether flushing a page from the InnoDB buffer pool also flushes other dirty pages in the same extent (default is 1): 0 - dirty pages in the same extent are not flushed,  1 - flush contiguous dirty pages in the same extent,  2 - flush dirty pages in the same extent.",
						},
						"innodb_ft_min_token_size": datasource.Int64Attribute{
							Computed:    true,
							Description: "Minimum length of words that are stored in an InnoDB FULLTEXT index. Changing this parameter will lead to a restart of the MySQL service.",
						},
						"innodb_ft_server_stopword_table": datasource.StringAttribute{
							Computed:    true,
							Description: "This option is used to specify your own InnoDB FULLTEXT index stopword list for all InnoDB tables.",
						},
						"innodb_lock_wait_timeout": datasource.Int64Attribute{
							Computed:    true,
							Description: "The length of time in seconds an InnoDB transaction waits for a row lock before giving up. Default is 120.",
						},
						"innodb_log_buffer_size": datasource.Int64Attribute{
							Computed:    true,
							Description: "The size in bytes of the buffer that InnoDB uses to write to the log files on disk.",
						},
						"innodb_online_alter_log_max_size": datasource.Int64Attribute{
							Computed:    true,
							Description: "The upper limit in bytes on the size of the temporary log files used during online DDL operations for InnoDB tables.",
						},
						"innodb_print_all_deadlocks": datasource.BoolAttribute{
							Computed:    true,
							Description: "When enabled, information about all deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.",
						},
						"innodb_read_io_threads": datasource.Int64Attribute{
							Computed:    true,
							Description: "The number of I/O threads for read operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
						},
						"innodb_rollback_on_timeout": datasource.BoolAttribute{
							Computed:    true,
							Description: "When enabled a transaction timeout causes InnoDB to abort and roll back the entire transaction. Changing this parameter will lead to a restart of the MySQL service.",
						},
						"innodb_thread_concurrency": datasource.Int64Attribute{
							Computed:    true,
							Description: "Defines the maximum number of threads permitted inside of InnoDB. Default is 0 (infinite concurrency - no limit).",
						},
						"innodb_write_io_threads": datasource.Int64Attribute{
							Computed:    true,
							Description: "The number of I/O threads for write operations in InnoDB. Default is 4. Changing this parameter will lead to a restart of the MySQL service.",
						},
						"interactive_timeout": datasource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds the server waits for activity on an interactive connection before closing it.",
						},
						"internal_tmp_mem_storage_engine": datasource.StringAttribute{
							Computed:    true,
							Description: "The storage engine for in-memory internal temporary tables.",
						},
						"long_query_time": datasource.Float64Attribute{
							Computed:    true,
							Description: "The slow_query_logs work as SQL statements that take more than long_query_time seconds to execute. Default is 10s.",
						},
						"max_allowed_packet": datasource.Int64Attribute{
							Computed:    true,
							Description: "Size of the largest message in bytes that can be received by the server. Default is 67108864 (64M).",
						},
						"max_heap_table_size": datasource.Int64Attribute{
							Computed:    true,
							Description: "Limits the size of internal in-memory tables. Also set tmp_table_size. Default is 16777216 (16M).",
						},
						"net_buffer_length": datasource.Int64Attribute{
							Computed:    true,
							Description: "Start sizes of connection buffer and result buffer. Default is 16384 (16K). Changing this parameter will lead to a restart of the MySQL service.",
						},
						"net_read_timeout": datasource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds to wait for more data from a connection before aborting the read.",
						},
						"net_write_timeout": datasource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds to wait for a block to be written to a connection before aborting the write.",
						},
						"slow_query_log": datasource.BoolAttribute{
							Computed:    true,
							Description: "Slow query log enables capturing of slow queries. Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off.",
						},
						"sort_buffer_size": datasource.Int64Attribute{
							Computed:    true,
							Description: "Sort buffer size in bytes for ORDER BY optimization. Default is 262144 (256K).",
						},
						"sql_mode": datasource.StringAttribute{
							Computed:    true,
							Description: "Global SQL mode. Set to empty to use MySQL server defaults. When creating a new service and not setting this field Aiven default SQL mode (strict, SQL standard compliant) will be assigned.",
						},
						"sql_require_primary_key": datasource.BoolAttribute{
							Computed:    true,
							Description: "Require primary key to be defined for new tables or old tables modified with ALTER TABLE and fail if missing. It is recommended to always have primary keys because various functionality may break if any large table is missing them.",
						},
						"tmp_table_size": datasource.Int64Attribute{
							Computed:    true,
							Description: "Limits the size of internal in-memory tables. Also set max_heap_table_size. Default is 16777216 (16M).",
						},
						"wait_timeout": datasource.Int64Attribute{
							Computed:    true,
							Description: "The number of seconds the server waits for activity on a noninteractive connection before closing it.",
						},
					}},
				},
				"private_access": datasource.SetNestedBlock{
					Description: "Allow access to selected service ports from private networks",
					NestedObject: datasource.NestedBlockObject{Attributes: map[string]datasource.Attribute{
						"mysql": datasource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysql with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations.",
						},
						"mysqlx": datasource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysqlx with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations.",
						},
						"prometheus": datasource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations.",
						},
					}},
				},
				"privatelink_access": datasource.SetNestedBlock{
					Description: "Allow access to selected service components through Privatelink",
					NestedObject: datasource.NestedBlockObject{Attributes: map[string]datasource.Attribute{
						"mysql": datasource.BoolAttribute{
							Computed:    true,
							Description: "Enable mysql.",
						},
						"mysqlx": datasource.BoolAttribute{
							Computed:    true,
							Description: "Enable mysqlx.",
						},
						"prometheus": datasource.BoolAttribute{
							Computed:    true,
							Description: "Enable prometheus.",
						},
					}},
				},
				"public_access": datasource.SetNestedBlock{
					Description: "Allow access to selected service ports from the public Internet",
					NestedObject: datasource.NestedBlockObject{Attributes: map[string]datasource.Attribute{
						"mysql": datasource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysql from the public internet for service nodes that are in a project VPC or another type of private network.",
						},
						"mysqlx": datasource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to mysqlx from the public internet for service nodes that are in a project VPC or another type of private network.",
						},
						"prometheus": datasource.BoolAttribute{
							Computed:    true,
							Description: "Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network.",
						},
					}},
				},
			},
		},
		Validators: []validator.Set{setvalidator.SizeAtMost(1)},
	}
}

// tfoUserConfig Mysql user configurable settings
type tfoUserConfig struct {
	AdditionalBackupRegions types.Set    `tfsdk:"additional_backup_regions"`
	AdminPassword           types.String `tfsdk:"admin_password"`
	AdminUsername           types.String `tfsdk:"admin_username"`
	BackupHour              types.Int64  `tfsdk:"backup_hour"`
	BackupMinute            types.Int64  `tfsdk:"backup_minute"`
	BinlogRetentionPeriod   types.Int64  `tfsdk:"binlog_retention_period"`
	IpFilter                types.Set    `tfsdk:"ip_filter"`
	Migration               types.Set    `tfsdk:"migration"`
	Mysql                   types.Set    `tfsdk:"mysql"`
	MysqlVersion            types.String `tfsdk:"mysql_version"`
	PrivateAccess           types.Set    `tfsdk:"private_access"`
	PrivatelinkAccess       types.Set    `tfsdk:"privatelink_access"`
	ProjectToForkFrom       types.String `tfsdk:"project_to_fork_from"`
	PublicAccess            types.Set    `tfsdk:"public_access"`
	RecoveryTargetTime      types.String `tfsdk:"recovery_target_time"`
	ServiceToForkFrom       types.String `tfsdk:"service_to_fork_from"`
	StaticIps               types.Bool   `tfsdk:"static_ips"`
}

// dtoUserConfig request/response object
type dtoUserConfig struct {
	AdditionalBackupRegions []string              `groups:"create,update" json:"additional_backup_regions,omitempty"`
	AdminPassword           *string               `groups:"create" json:"admin_password,omitempty"`
	AdminUsername           *string               `groups:"create" json:"admin_username,omitempty"`
	BackupHour              *int64                `groups:"create,update" json:"backup_hour,omitempty"`
	BackupMinute            *int64                `groups:"create,update" json:"backup_minute,omitempty"`
	BinlogRetentionPeriod   *int64                `groups:"create,update" json:"binlog_retention_period,omitempty"`
	IpFilter                []*dtoIpFilter        `groups:"create,update" json:"ip_filter,omitempty"`
	Migration               *dtoMigration         `groups:"create,update" json:"migration,omitempty"`
	Mysql                   *dtoMysql             `groups:"create,update" json:"mysql,omitempty"`
	MysqlVersion            *string               `groups:"create,update" json:"mysql_version,omitempty"`
	PrivateAccess           *dtoPrivateAccess     `groups:"create,update" json:"private_access,omitempty"`
	PrivatelinkAccess       *dtoPrivatelinkAccess `groups:"create,update" json:"privatelink_access,omitempty"`
	ProjectToForkFrom       *string               `groups:"create" json:"project_to_fork_from,omitempty"`
	PublicAccess            *dtoPublicAccess      `groups:"create,update" json:"public_access,omitempty"`
	RecoveryTargetTime      *string               `groups:"create" json:"recovery_target_time,omitempty"`
	ServiceToForkFrom       *string               `groups:"create" json:"service_to_fork_from,omitempty"`
	StaticIps               *bool                 `groups:"create,update" json:"static_ips,omitempty"`
}

// expandUserConfig expands tf object into dto object
func expandUserConfig(ctx context.Context, diags diag.Diagnostics, o *tfoUserConfig) *dtoUserConfig {
	additionalBackupRegionsVar := schemautil.ExpandSet[string](ctx, diags, o.AdditionalBackupRegions)
	if diags.HasError() {
		return nil
	}
	ipFilterVar := schemautil.ExpandSetNested(ctx, diags, expandIpFilter, o.IpFilter)
	if diags.HasError() {
		return nil
	}
	migrationVar := schemautil.ExpandSetBlockNested(ctx, diags, expandMigration, o.Migration)
	if diags.HasError() {
		return nil
	}
	mysqlVar := schemautil.ExpandSetBlockNested(ctx, diags, expandMysql, o.Mysql)
	if diags.HasError() {
		return nil
	}
	privateAccessVar := schemautil.ExpandSetBlockNested(ctx, diags, expandPrivateAccess, o.PrivateAccess)
	if diags.HasError() {
		return nil
	}
	privatelinkAccessVar := schemautil.ExpandSetBlockNested(ctx, diags, expandPrivatelinkAccess, o.PrivatelinkAccess)
	if diags.HasError() {
		return nil
	}
	publicAccessVar := schemautil.ExpandSetBlockNested(ctx, diags, expandPublicAccess, o.PublicAccess)
	if diags.HasError() {
		return nil
	}
	return &dtoUserConfig{
		AdditionalBackupRegions: additionalBackupRegionsVar,
		AdminPassword:           schemautil.ValueStringPointer(o.AdminPassword),
		AdminUsername:           schemautil.ValueStringPointer(o.AdminUsername),
		BackupHour:              schemautil.ValueInt64Pointer(o.BackupHour),
		BackupMinute:            schemautil.ValueInt64Pointer(o.BackupMinute),
		BinlogRetentionPeriod:   schemautil.ValueInt64Pointer(o.BinlogRetentionPeriod),
		IpFilter:                ipFilterVar,
		Migration:               migrationVar,
		Mysql:                   mysqlVar,
		MysqlVersion:            schemautil.ValueStringPointer(o.MysqlVersion),
		PrivateAccess:           privateAccessVar,
		PrivatelinkAccess:       privatelinkAccessVar,
		ProjectToForkFrom:       schemautil.ValueStringPointer(o.ProjectToForkFrom),
		PublicAccess:            publicAccessVar,
		RecoveryTargetTime:      schemautil.ValueStringPointer(o.RecoveryTargetTime),
		ServiceToForkFrom:       schemautil.ValueStringPointer(o.ServiceToForkFrom),
		StaticIps:               schemautil.ValueBoolPointer(o.StaticIps),
	}
}

// flattenUserConfig flattens dto object into tf object
func flattenUserConfig(ctx context.Context, diags diag.Diagnostics, o *dtoUserConfig) *tfoUserConfig {
	additionalBackupRegionsVar, d := types.SetValueFrom(ctx, types.StringType, o.AdditionalBackupRegions)
	diags.Append(d...)
	if diags.HasError() {
		return nil
	}
	ipFilterVar := schemautil.FlattenSetNested(ctx, diags, flattenIpFilter, o.IpFilter, ipFilterAttrs)
	if diags.HasError() {
		return nil
	}
	migrationVar := schemautil.FlattenSetBlockNested(ctx, diags, flattenMigration, o.Migration, migrationAttrs)
	if diags.HasError() {
		return nil
	}
	mysqlVar := schemautil.FlattenSetBlockNested(ctx, diags, flattenMysql, o.Mysql, mysqlAttrs)
	if diags.HasError() {
		return nil
	}
	privateAccessVar := schemautil.FlattenSetBlockNested(ctx, diags, flattenPrivateAccess, o.PrivateAccess, privateAccessAttrs)
	if diags.HasError() {
		return nil
	}
	privatelinkAccessVar := schemautil.FlattenSetBlockNested(ctx, diags, flattenPrivatelinkAccess, o.PrivatelinkAccess, privatelinkAccessAttrs)
	if diags.HasError() {
		return nil
	}
	publicAccessVar := schemautil.FlattenSetBlockNested(ctx, diags, flattenPublicAccess, o.PublicAccess, publicAccessAttrs)
	if diags.HasError() {
		return nil
	}
	return &tfoUserConfig{
		AdditionalBackupRegions: additionalBackupRegionsVar,
		AdminPassword:           types.StringPointerValue(o.AdminPassword),
		AdminUsername:           types.StringPointerValue(o.AdminUsername),
		BackupHour:              types.Int64PointerValue(o.BackupHour),
		BackupMinute:            types.Int64PointerValue(o.BackupMinute),
		BinlogRetentionPeriod:   types.Int64PointerValue(o.BinlogRetentionPeriod),
		IpFilter:                ipFilterVar,
		Migration:               migrationVar,
		Mysql:                   mysqlVar,
		MysqlVersion:            types.StringPointerValue(o.MysqlVersion),
		PrivateAccess:           privateAccessVar,
		PrivatelinkAccess:       privatelinkAccessVar,
		ProjectToForkFrom:       types.StringPointerValue(o.ProjectToForkFrom),
		PublicAccess:            publicAccessVar,
		RecoveryTargetTime:      types.StringPointerValue(o.RecoveryTargetTime),
		ServiceToForkFrom:       types.StringPointerValue(o.ServiceToForkFrom),
		StaticIps:               types.BoolPointerValue(o.StaticIps),
	}
}

var userConfigAttrs = map[string]attr.Type{
	"additional_backup_regions": types.SetType{ElemType: types.StringType},
	"admin_password":            types.StringType,
	"admin_username":            types.StringType,
	"backup_hour":               types.Int64Type,
	"backup_minute":             types.Int64Type,
	"binlog_retention_period":   types.Int64Type,
	"ip_filter":                 types.SetType{ElemType: types.ObjectType{AttrTypes: ipFilterAttrs}},
	"migration":                 types.SetType{ElemType: types.ObjectType{AttrTypes: migrationAttrs}},
	"mysql":                     types.SetType{ElemType: types.ObjectType{AttrTypes: mysqlAttrs}},
	"mysql_version":             types.StringType,
	"private_access":            types.SetType{ElemType: types.ObjectType{AttrTypes: privateAccessAttrs}},
	"privatelink_access":        types.SetType{ElemType: types.ObjectType{AttrTypes: privatelinkAccessAttrs}},
	"project_to_fork_from":      types.StringType,
	"public_access":             types.SetType{ElemType: types.ObjectType{AttrTypes: publicAccessAttrs}},
	"recovery_target_time":      types.StringType,
	"service_to_fork_from":      types.StringType,
	"static_ips":                types.BoolType,
}

// tfoIpFilter CIDR address block, either as a string, or in a dict with an optional description field
type tfoIpFilter struct {
	Description types.String `tfsdk:"description"`
	Network     types.String `tfsdk:"network"`
}

// dtoIpFilter request/response object
type dtoIpFilter struct {
	Description *string `groups:"create,update" json:"description,omitempty"`
	Network     string  `groups:"create,update" json:"network"`
}

func (d *dtoIpFilter) UnmarshalJSON(data []byte) error {
	var s string
	err := json.Unmarshal(data, &s)
	if err == nil {
		d.Network = s
		return nil
	}

	type obj dtoIpFilter
	o := &struct {
		Description *string `groups:"create,update" json:"description,omitempty"`
		Network     string  `groups:"create,update" json:"network"`
	}{}
	err = json.Unmarshal(data, o)
	if err != nil {
		return err
	}

	d.Description = o.Description
	d.Network = o.Network
	return nil
}

// expandIpFilter expands tf object into dto object
func expandIpFilter(ctx context.Context, diags diag.Diagnostics, o *tfoIpFilter) *dtoIpFilter {
	return &dtoIpFilter{
		Description: schemautil.ValueStringPointer(o.Description),
		Network:     o.Network.ValueString(),
	}
}

// flattenIpFilter flattens dto object into tf object
func flattenIpFilter(ctx context.Context, diags diag.Diagnostics, o *dtoIpFilter) *tfoIpFilter {
	return &tfoIpFilter{
		Description: types.StringPointerValue(o.Description),
		Network:     types.StringValue(o.Network),
	}
}

var ipFilterAttrs = map[string]attr.Type{
	"description": types.StringType,
	"network":     types.StringType,
}

// tfoMigration Migrate data from existing server
type tfoMigration struct {
	Dbname    types.String `tfsdk:"dbname"`
	Host      types.String `tfsdk:"host"`
	IgnoreDbs types.String `tfsdk:"ignore_dbs"`
	Method    types.String `tfsdk:"method"`
	Password  types.String `tfsdk:"password"`
	Port      types.Int64  `tfsdk:"port"`
	Ssl       types.Bool   `tfsdk:"ssl"`
	Username  types.String `tfsdk:"username"`
}

// dtoMigration request/response object
type dtoMigration struct {
	Dbname    *string `groups:"create,update" json:"dbname,omitempty"`
	Host      string  `groups:"create,update" json:"host"`
	IgnoreDbs *string `groups:"create,update" json:"ignore_dbs,omitempty"`
	Method    *string `groups:"create,update" json:"method,omitempty"`
	Password  *string `groups:"create,update" json:"password,omitempty"`
	Port      int64   `groups:"create,update" json:"port"`
	Ssl       *bool   `groups:"create,update" json:"ssl,omitempty"`
	Username  *string `groups:"create,update" json:"username,omitempty"`
}

// expandMigration expands tf object into dto object
func expandMigration(ctx context.Context, diags diag.Diagnostics, o *tfoMigration) *dtoMigration {
	return &dtoMigration{
		Dbname:    schemautil.ValueStringPointer(o.Dbname),
		Host:      o.Host.ValueString(),
		IgnoreDbs: schemautil.ValueStringPointer(o.IgnoreDbs),
		Method:    schemautil.ValueStringPointer(o.Method),
		Password:  schemautil.ValueStringPointer(o.Password),
		Port:      o.Port.ValueInt64(),
		Ssl:       schemautil.ValueBoolPointer(o.Ssl),
		Username:  schemautil.ValueStringPointer(o.Username),
	}
}

// flattenMigration flattens dto object into tf object
func flattenMigration(ctx context.Context, diags diag.Diagnostics, o *dtoMigration) *tfoMigration {
	return &tfoMigration{
		Dbname:    types.StringPointerValue(o.Dbname),
		Host:      types.StringValue(o.Host),
		IgnoreDbs: types.StringPointerValue(o.IgnoreDbs),
		Method:    types.StringPointerValue(o.Method),
		Password:  types.StringPointerValue(o.Password),
		Port:      types.Int64Value(o.Port),
		Ssl:       types.BoolPointerValue(o.Ssl),
		Username:  types.StringPointerValue(o.Username),
	}
}

var migrationAttrs = map[string]attr.Type{
	"dbname":     types.StringType,
	"host":       types.StringType,
	"ignore_dbs": types.StringType,
	"method":     types.StringType,
	"password":   types.StringType,
	"port":       types.Int64Type,
	"ssl":        types.BoolType,
	"username":   types.StringType,
}

// tfoMysql mysql.conf configuration values
type tfoMysql struct {
	ConnectTimeout               types.Int64   `tfsdk:"connect_timeout"`
	DefaultTimeZone              types.String  `tfsdk:"default_time_zone"`
	GroupConcatMaxLen            types.Int64   `tfsdk:"group_concat_max_len"`
	InformationSchemaStatsExpiry types.Int64   `tfsdk:"information_schema_stats_expiry"`
	InnodbChangeBufferMaxSize    types.Int64   `tfsdk:"innodb_change_buffer_max_size"`
	InnodbFlushNeighbors         types.Int64   `tfsdk:"innodb_flush_neighbors"`
	InnodbFtMinTokenSize         types.Int64   `tfsdk:"innodb_ft_min_token_size"`
	InnodbFtServerStopwordTable  types.String  `tfsdk:"innodb_ft_server_stopword_table"`
	InnodbLockWaitTimeout        types.Int64   `tfsdk:"innodb_lock_wait_timeout"`
	InnodbLogBufferSize          types.Int64   `tfsdk:"innodb_log_buffer_size"`
	InnodbOnlineAlterLogMaxSize  types.Int64   `tfsdk:"innodb_online_alter_log_max_size"`
	InnodbPrintAllDeadlocks      types.Bool    `tfsdk:"innodb_print_all_deadlocks"`
	InnodbReadIoThreads          types.Int64   `tfsdk:"innodb_read_io_threads"`
	InnodbRollbackOnTimeout      types.Bool    `tfsdk:"innodb_rollback_on_timeout"`
	InnodbThreadConcurrency      types.Int64   `tfsdk:"innodb_thread_concurrency"`
	InnodbWriteIoThreads         types.Int64   `tfsdk:"innodb_write_io_threads"`
	InteractiveTimeout           types.Int64   `tfsdk:"interactive_timeout"`
	InternalTmpMemStorageEngine  types.String  `tfsdk:"internal_tmp_mem_storage_engine"`
	LongQueryTime                types.Float64 `tfsdk:"long_query_time"`
	MaxAllowedPacket             types.Int64   `tfsdk:"max_allowed_packet"`
	MaxHeapTableSize             types.Int64   `tfsdk:"max_heap_table_size"`
	NetBufferLength              types.Int64   `tfsdk:"net_buffer_length"`
	NetReadTimeout               types.Int64   `tfsdk:"net_read_timeout"`
	NetWriteTimeout              types.Int64   `tfsdk:"net_write_timeout"`
	SlowQueryLog                 types.Bool    `tfsdk:"slow_query_log"`
	SortBufferSize               types.Int64   `tfsdk:"sort_buffer_size"`
	SqlMode                      types.String  `tfsdk:"sql_mode"`
	SqlRequirePrimaryKey         types.Bool    `tfsdk:"sql_require_primary_key"`
	TmpTableSize                 types.Int64   `tfsdk:"tmp_table_size"`
	WaitTimeout                  types.Int64   `tfsdk:"wait_timeout"`
}

// dtoMysql request/response object
type dtoMysql struct {
	ConnectTimeout               *int64   `groups:"create,update" json:"connect_timeout,omitempty"`
	DefaultTimeZone              *string  `groups:"create,update" json:"default_time_zone,omitempty"`
	GroupConcatMaxLen            *int64   `groups:"create,update" json:"group_concat_max_len,omitempty"`
	InformationSchemaStatsExpiry *int64   `groups:"create,update" json:"information_schema_stats_expiry,omitempty"`
	InnodbChangeBufferMaxSize    *int64   `groups:"create,update" json:"innodb_change_buffer_max_size,omitempty"`
	InnodbFlushNeighbors         *int64   `groups:"create,update" json:"innodb_flush_neighbors,omitempty"`
	InnodbFtMinTokenSize         *int64   `groups:"create,update" json:"innodb_ft_min_token_size,omitempty"`
	InnodbFtServerStopwordTable  *string  `groups:"create,update" json:"innodb_ft_server_stopword_table,omitempty"`
	InnodbLockWaitTimeout        *int64   `groups:"create,update" json:"innodb_lock_wait_timeout,omitempty"`
	InnodbLogBufferSize          *int64   `groups:"create,update" json:"innodb_log_buffer_size,omitempty"`
	InnodbOnlineAlterLogMaxSize  *int64   `groups:"create,update" json:"innodb_online_alter_log_max_size,omitempty"`
	InnodbPrintAllDeadlocks      *bool    `groups:"create,update" json:"innodb_print_all_deadlocks,omitempty"`
	InnodbReadIoThreads          *int64   `groups:"create,update" json:"innodb_read_io_threads,omitempty"`
	InnodbRollbackOnTimeout      *bool    `groups:"create,update" json:"innodb_rollback_on_timeout,omitempty"`
	InnodbThreadConcurrency      *int64   `groups:"create,update" json:"innodb_thread_concurrency,omitempty"`
	InnodbWriteIoThreads         *int64   `groups:"create,update" json:"innodb_write_io_threads,omitempty"`
	InteractiveTimeout           *int64   `groups:"create,update" json:"interactive_timeout,omitempty"`
	InternalTmpMemStorageEngine  *string  `groups:"create,update" json:"internal_tmp_mem_storage_engine,omitempty"`
	LongQueryTime                *float64 `groups:"create,update" json:"long_query_time,omitempty"`
	MaxAllowedPacket             *int64   `groups:"create,update" json:"max_allowed_packet,omitempty"`
	MaxHeapTableSize             *int64   `groups:"create,update" json:"max_heap_table_size,omitempty"`
	NetBufferLength              *int64   `groups:"create,update" json:"net_buffer_length,omitempty"`
	NetReadTimeout               *int64   `groups:"create,update" json:"net_read_timeout,omitempty"`
	NetWriteTimeout              *int64   `groups:"create,update" json:"net_write_timeout,omitempty"`
	SlowQueryLog                 *bool    `groups:"create,update" json:"slow_query_log,omitempty"`
	SortBufferSize               *int64   `groups:"create,update" json:"sort_buffer_size,omitempty"`
	SqlMode                      *string  `groups:"create,update" json:"sql_mode,omitempty"`
	SqlRequirePrimaryKey         *bool    `groups:"create,update" json:"sql_require_primary_key,omitempty"`
	TmpTableSize                 *int64   `groups:"create,update" json:"tmp_table_size,omitempty"`
	WaitTimeout                  *int64   `groups:"create,update" json:"wait_timeout,omitempty"`
}

// expandMysql expands tf object into dto object
func expandMysql(ctx context.Context, diags diag.Diagnostics, o *tfoMysql) *dtoMysql {
	return &dtoMysql{
		ConnectTimeout:               schemautil.ValueInt64Pointer(o.ConnectTimeout),
		DefaultTimeZone:              schemautil.ValueStringPointer(o.DefaultTimeZone),
		GroupConcatMaxLen:            schemautil.ValueInt64Pointer(o.GroupConcatMaxLen),
		InformationSchemaStatsExpiry: schemautil.ValueInt64Pointer(o.InformationSchemaStatsExpiry),
		InnodbChangeBufferMaxSize:    schemautil.ValueInt64Pointer(o.InnodbChangeBufferMaxSize),
		InnodbFlushNeighbors:         schemautil.ValueInt64Pointer(o.InnodbFlushNeighbors),
		InnodbFtMinTokenSize:         schemautil.ValueInt64Pointer(o.InnodbFtMinTokenSize),
		InnodbFtServerStopwordTable:  schemautil.ValueStringPointer(o.InnodbFtServerStopwordTable),
		InnodbLockWaitTimeout:        schemautil.ValueInt64Pointer(o.InnodbLockWaitTimeout),
		InnodbLogBufferSize:          schemautil.ValueInt64Pointer(o.InnodbLogBufferSize),
		InnodbOnlineAlterLogMaxSize:  schemautil.ValueInt64Pointer(o.InnodbOnlineAlterLogMaxSize),
		InnodbPrintAllDeadlocks:      schemautil.ValueBoolPointer(o.InnodbPrintAllDeadlocks),
		InnodbReadIoThreads:          schemautil.ValueInt64Pointer(o.InnodbReadIoThreads),
		InnodbRollbackOnTimeout:      schemautil.ValueBoolPointer(o.InnodbRollbackOnTimeout),
		InnodbThreadConcurrency:      schemautil.ValueInt64Pointer(o.InnodbThreadConcurrency),
		InnodbWriteIoThreads:         schemautil.ValueInt64Pointer(o.InnodbWriteIoThreads),
		InteractiveTimeout:           schemautil.ValueInt64Pointer(o.InteractiveTimeout),
		InternalTmpMemStorageEngine:  schemautil.ValueStringPointer(o.InternalTmpMemStorageEngine),
		LongQueryTime:                schemautil.ValueFloat64Pointer(o.LongQueryTime),
		MaxAllowedPacket:             schemautil.ValueInt64Pointer(o.MaxAllowedPacket),
		MaxHeapTableSize:             schemautil.ValueInt64Pointer(o.MaxHeapTableSize),
		NetBufferLength:              schemautil.ValueInt64Pointer(o.NetBufferLength),
		NetReadTimeout:               schemautil.ValueInt64Pointer(o.NetReadTimeout),
		NetWriteTimeout:              schemautil.ValueInt64Pointer(o.NetWriteTimeout),
		SlowQueryLog:                 schemautil.ValueBoolPointer(o.SlowQueryLog),
		SortBufferSize:               schemautil.ValueInt64Pointer(o.SortBufferSize),
		SqlMode:                      schemautil.ValueStringPointer(o.SqlMode),
		SqlRequirePrimaryKey:         schemautil.ValueBoolPointer(o.SqlRequirePrimaryKey),
		TmpTableSize:                 schemautil.ValueInt64Pointer(o.TmpTableSize),
		WaitTimeout:                  schemautil.ValueInt64Pointer(o.WaitTimeout),
	}
}

// flattenMysql flattens dto object into tf object
func flattenMysql(ctx context.Context, diags diag.Diagnostics, o *dtoMysql) *tfoMysql {
	return &tfoMysql{
		ConnectTimeout:               types.Int64PointerValue(o.ConnectTimeout),
		DefaultTimeZone:              types.StringPointerValue(o.DefaultTimeZone),
		GroupConcatMaxLen:            types.Int64PointerValue(o.GroupConcatMaxLen),
		InformationSchemaStatsExpiry: types.Int64PointerValue(o.InformationSchemaStatsExpiry),
		InnodbChangeBufferMaxSize:    types.Int64PointerValue(o.InnodbChangeBufferMaxSize),
		InnodbFlushNeighbors:         types.Int64PointerValue(o.InnodbFlushNeighbors),
		InnodbFtMinTokenSize:         types.Int64PointerValue(o.InnodbFtMinTokenSize),
		InnodbFtServerStopwordTable:  types.StringPointerValue(o.InnodbFtServerStopwordTable),
		InnodbLockWaitTimeout:        types.Int64PointerValue(o.InnodbLockWaitTimeout),
		InnodbLogBufferSize:          types.Int64PointerValue(o.InnodbLogBufferSize),
		InnodbOnlineAlterLogMaxSize:  types.Int64PointerValue(o.InnodbOnlineAlterLogMaxSize),
		InnodbPrintAllDeadlocks:      types.BoolPointerValue(o.InnodbPrintAllDeadlocks),
		InnodbReadIoThreads:          types.Int64PointerValue(o.InnodbReadIoThreads),
		InnodbRollbackOnTimeout:      types.BoolPointerValue(o.InnodbRollbackOnTimeout),
		InnodbThreadConcurrency:      types.Int64PointerValue(o.InnodbThreadConcurrency),
		InnodbWriteIoThreads:         types.Int64PointerValue(o.InnodbWriteIoThreads),
		InteractiveTimeout:           types.Int64PointerValue(o.InteractiveTimeout),
		InternalTmpMemStorageEngine:  types.StringPointerValue(o.InternalTmpMemStorageEngine),
		LongQueryTime:                types.Float64PointerValue(o.LongQueryTime),
		MaxAllowedPacket:             types.Int64PointerValue(o.MaxAllowedPacket),
		MaxHeapTableSize:             types.Int64PointerValue(o.MaxHeapTableSize),
		NetBufferLength:              types.Int64PointerValue(o.NetBufferLength),
		NetReadTimeout:               types.Int64PointerValue(o.NetReadTimeout),
		NetWriteTimeout:              types.Int64PointerValue(o.NetWriteTimeout),
		SlowQueryLog:                 types.BoolPointerValue(o.SlowQueryLog),
		SortBufferSize:               types.Int64PointerValue(o.SortBufferSize),
		SqlMode:                      types.StringPointerValue(o.SqlMode),
		SqlRequirePrimaryKey:         types.BoolPointerValue(o.SqlRequirePrimaryKey),
		TmpTableSize:                 types.Int64PointerValue(o.TmpTableSize),
		WaitTimeout:                  types.Int64PointerValue(o.WaitTimeout),
	}
}

var mysqlAttrs = map[string]attr.Type{
	"connect_timeout":                  types.Int64Type,
	"default_time_zone":                types.StringType,
	"group_concat_max_len":             types.Int64Type,
	"information_schema_stats_expiry":  types.Int64Type,
	"innodb_change_buffer_max_size":    types.Int64Type,
	"innodb_flush_neighbors":           types.Int64Type,
	"innodb_ft_min_token_size":         types.Int64Type,
	"innodb_ft_server_stopword_table":  types.StringType,
	"innodb_lock_wait_timeout":         types.Int64Type,
	"innodb_log_buffer_size":           types.Int64Type,
	"innodb_online_alter_log_max_size": types.Int64Type,
	"innodb_print_all_deadlocks":       types.BoolType,
	"innodb_read_io_threads":           types.Int64Type,
	"innodb_rollback_on_timeout":       types.BoolType,
	"innodb_thread_concurrency":        types.Int64Type,
	"innodb_write_io_threads":          types.Int64Type,
	"interactive_timeout":              types.Int64Type,
	"internal_tmp_mem_storage_engine":  types.StringType,
	"long_query_time":                  types.Float64Type,
	"max_allowed_packet":               types.Int64Type,
	"max_heap_table_size":              types.Int64Type,
	"net_buffer_length":                types.Int64Type,
	"net_read_timeout":                 types.Int64Type,
	"net_write_timeout":                types.Int64Type,
	"slow_query_log":                   types.BoolType,
	"sort_buffer_size":                 types.Int64Type,
	"sql_mode":                         types.StringType,
	"sql_require_primary_key":          types.BoolType,
	"tmp_table_size":                   types.Int64Type,
	"wait_timeout":                     types.Int64Type,
}

// tfoPrivateAccess Allow access to selected service ports from private networks
type tfoPrivateAccess struct {
	Mysql      types.Bool `tfsdk:"mysql"`
	Mysqlx     types.Bool `tfsdk:"mysqlx"`
	Prometheus types.Bool `tfsdk:"prometheus"`
}

// dtoPrivateAccess request/response object
type dtoPrivateAccess struct {
	Mysql      *bool `groups:"create,update" json:"mysql,omitempty"`
	Mysqlx     *bool `groups:"create,update" json:"mysqlx,omitempty"`
	Prometheus *bool `groups:"create,update" json:"prometheus,omitempty"`
}

// expandPrivateAccess expands tf object into dto object
func expandPrivateAccess(ctx context.Context, diags diag.Diagnostics, o *tfoPrivateAccess) *dtoPrivateAccess {
	return &dtoPrivateAccess{
		Mysql:      schemautil.ValueBoolPointer(o.Mysql),
		Mysqlx:     schemautil.ValueBoolPointer(o.Mysqlx),
		Prometheus: schemautil.ValueBoolPointer(o.Prometheus),
	}
}

// flattenPrivateAccess flattens dto object into tf object
func flattenPrivateAccess(ctx context.Context, diags diag.Diagnostics, o *dtoPrivateAccess) *tfoPrivateAccess {
	return &tfoPrivateAccess{
		Mysql:      types.BoolPointerValue(o.Mysql),
		Mysqlx:     types.BoolPointerValue(o.Mysqlx),
		Prometheus: types.BoolPointerValue(o.Prometheus),
	}
}

var privateAccessAttrs = map[string]attr.Type{
	"mysql":      types.BoolType,
	"mysqlx":     types.BoolType,
	"prometheus": types.BoolType,
}

// tfoPrivatelinkAccess Allow access to selected service components through Privatelink
type tfoPrivatelinkAccess struct {
	Mysql      types.Bool `tfsdk:"mysql"`
	Mysqlx     types.Bool `tfsdk:"mysqlx"`
	Prometheus types.Bool `tfsdk:"prometheus"`
}

// dtoPrivatelinkAccess request/response object
type dtoPrivatelinkAccess struct {
	Mysql      *bool `groups:"create,update" json:"mysql,omitempty"`
	Mysqlx     *bool `groups:"create,update" json:"mysqlx,omitempty"`
	Prometheus *bool `groups:"create,update" json:"prometheus,omitempty"`
}

// expandPrivatelinkAccess expands tf object into dto object
func expandPrivatelinkAccess(ctx context.Context, diags diag.Diagnostics, o *tfoPrivatelinkAccess) *dtoPrivatelinkAccess {
	return &dtoPrivatelinkAccess{
		Mysql:      schemautil.ValueBoolPointer(o.Mysql),
		Mysqlx:     schemautil.ValueBoolPointer(o.Mysqlx),
		Prometheus: schemautil.ValueBoolPointer(o.Prometheus),
	}
}

// flattenPrivatelinkAccess flattens dto object into tf object
func flattenPrivatelinkAccess(ctx context.Context, diags diag.Diagnostics, o *dtoPrivatelinkAccess) *tfoPrivatelinkAccess {
	return &tfoPrivatelinkAccess{
		Mysql:      types.BoolPointerValue(o.Mysql),
		Mysqlx:     types.BoolPointerValue(o.Mysqlx),
		Prometheus: types.BoolPointerValue(o.Prometheus),
	}
}

var privatelinkAccessAttrs = map[string]attr.Type{
	"mysql":      types.BoolType,
	"mysqlx":     types.BoolType,
	"prometheus": types.BoolType,
}

// tfoPublicAccess Allow access to selected service ports from the public Internet
type tfoPublicAccess struct {
	Mysql      types.Bool `tfsdk:"mysql"`
	Mysqlx     types.Bool `tfsdk:"mysqlx"`
	Prometheus types.Bool `tfsdk:"prometheus"`
}

// dtoPublicAccess request/response object
type dtoPublicAccess struct {
	Mysql      *bool `groups:"create,update" json:"mysql,omitempty"`
	Mysqlx     *bool `groups:"create,update" json:"mysqlx,omitempty"`
	Prometheus *bool `groups:"create,update" json:"prometheus,omitempty"`
}

// expandPublicAccess expands tf object into dto object
func expandPublicAccess(ctx context.Context, diags diag.Diagnostics, o *tfoPublicAccess) *dtoPublicAccess {
	return &dtoPublicAccess{
		Mysql:      schemautil.ValueBoolPointer(o.Mysql),
		Mysqlx:     schemautil.ValueBoolPointer(o.Mysqlx),
		Prometheus: schemautil.ValueBoolPointer(o.Prometheus),
	}
}

// flattenPublicAccess flattens dto object into tf object
func flattenPublicAccess(ctx context.Context, diags diag.Diagnostics, o *dtoPublicAccess) *tfoPublicAccess {
	return &tfoPublicAccess{
		Mysql:      types.BoolPointerValue(o.Mysql),
		Mysqlx:     types.BoolPointerValue(o.Mysqlx),
		Prometheus: types.BoolPointerValue(o.Prometheus),
	}
}

var publicAccessAttrs = map[string]attr.Type{
	"mysql":      types.BoolType,
	"mysqlx":     types.BoolType,
	"prometheus": types.BoolType,
}

// Expand public function that converts tf object into dto
func Expand(ctx context.Context, diags diag.Diagnostics, set types.Set) *dtoUserConfig {
	return schemautil.ExpandSetBlockNested[tfoUserConfig, dtoUserConfig](ctx, diags, expandUserConfig, set)
}

// Flatten public function that converts dto into tf object
func Flatten(ctx context.Context, diags diag.Diagnostics, m map[string]any) types.Set {
	o := new(dtoUserConfig)
	err := schemautil.MapToDTO(m, o)
	if err != nil {
		diags.AddError("Failed to marshal map user config to dto", err.Error())
		return types.SetNull(types.ObjectType{AttrTypes: userConfigAttrs})
	}
	return schemautil.FlattenSetBlockNested[dtoUserConfig, tfoUserConfig](ctx, diags, flattenUserConfig, o, userConfigAttrs)
}
