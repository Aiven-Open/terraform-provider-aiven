---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "aiven_flink_table Resource - terraform-provider-aiven"
subcategory: ""
description: |-
  The Flink Table resource allows the creation and management of Aiven Tables.
---

# aiven_flink_table (Resource)

The Flink Table resource allows the creation and management of Aiven Tables.

## Example Usage

```terraform
resource "aiven_flink_table" "table" {
  project        = data.aiven_project.pr1.project
  service_name   = aiven_flink.flink.service_name
  table_name     = "<TABLE_NAME>"
  integration_id = aiven_service_integration.flink_kafka.service_id

  # valid if the service integration refers to a postgres or mysql service
  jdbc_table = "<JDBC_TABLE_NAME>"

  # valid if the service integration refers to a kafka service
  kafka_topic = aiven_kafka_topic.table_topic.topic_name

  schema_sql = <<EOF
      `+"`cpu`"+` INT,
      `+"`node`"+` INT,
      `+"`occurred_at`"+` TIMESTAMP(3) METADATA FROM 'timestamp',
      WATERMARK FOR `+"`occurred_at`"+` AS `+"`occurred_at`"+` - INTERVAL '5' SECOND
    EOF
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `integration_id` (String) The id of the service integration that is used with this table. It must have the service integration type `flink`. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
- `project` (String) Identifies the project this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
- `schema_sql` (String) The SQL statement to create the table. This property cannot be changed, doing so forces recreation of the resource.
- `service_name` (String) Specifies the name of the service that this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
- `table_name` (String) Specifies the name of the table. This property cannot be changed, doing so forces recreation of the resource.

### Optional

- `jdbc_table` (String) Name of the jdbc table that is to be connected to this table. Valid if the service integration id refers to a mysql or postgres service. This property cannot be changed, doing so forces recreation of the resource.
- `kafka_connector_type` (String) When used as a source, upsert Kafka connectors update values that use an existing key and delete values that are null. For sinks, the connector correspondingly writes update or delete messages in a compacted topic. If no matching key is found, the values are added as new entries. For more information, see the Apache Flink documentation. The possible values are `kafka` and `upsert-kafka`. This property cannot be changed, doing so forces recreation of the resource.
- `kafka_key_fields` (List of String) Defines an explicit list of physical columns from the table schema that configure the data type for the key format. This property cannot be changed, doing so forces recreation of the resource.
- `kafka_key_format` (String) Kafka Key Format. The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
- `kafka_startup_mode` (String) Startup mode. The possible values are `earliest-offset`, `latest-offset`, `group-offsets` and `timestamp`. This property cannot be changed, doing so forces recreation of the resource.
- `kafka_topic` (String) Name of the kafka topic that is to be connected to this table. Valid if the service integration id refers to a kafka service. This property cannot be changed, doing so forces recreation of the resource.
- `kafka_value_fields_include` (String) Controls how key columns are handled in the message value. Select ALL to include the physical columns of the table schema in the message value. Select EXCEPT_KEY to exclude the physical columns of the table schema from the message value. This is the default for upsert Kafka connectors. The possible values are `[ALL EXCEPT_KEY]`. This property cannot be changed, doing so forces recreation of the resource.
- `kafka_value_format` (String) Kafka Value Format. The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
- `like_options` (String) [LIKE](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/create/#like) statement for table creation. This property cannot be changed, doing so forces recreation of the resource.
- `opensearch_index` (String) For an OpenSearch table, the OpenSearch index the table outputs to. This property cannot be changed, doing so forces recreation of the resource.
- `upsert_kafka` (Block Set, Max: 1) Kafka upsert connector configuration. (see [below for nested schema](#nestedblock--upsert_kafka))

### Read-Only

- `id` (String) The ID of this resource.
- `table_id` (String) The Table ID of the flink table in the flink service.

<a id="nestedblock--upsert_kafka"></a>
### Nested Schema for `upsert_kafka`

Optional:

- `key_fields` (List of String) Defines the columns from the SQL schema of the data table that are considered keys in the Kafka messages. This property cannot be changed, doing so forces recreation of the resource.
- `key_format` (String) Sets the format that is used to convert the key part of Kafka messages. The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
- `scan_startup_mode` (String) Controls the startup method for the Kafka consumer that Aiven for Apache Flink is using. The possible values are `earliest-offset`, `latest-offset`, `group-offsets` and `timestamp`. This property cannot be changed, doing so forces recreation of the resource.
- `topic` (String) Topic name. This property cannot be changed, doing so forces recreation of the resource.
- `value_fields_include` (String) Controls how key columns are handled in the message value. Select ALL to include the physical columns of the table schema in the message value. Select EXCEPT_KEY to exclude the physical columns of the table schema from the message value. This is the default for upsert Kafka connectors. The possible values are `[ALL EXCEPT_KEY]`. This property cannot be changed, doing so forces recreation of the resource.
- `value_format` (String) Sets the format that is used to convert the value part of Kafka messages. The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.

## Import

Import is supported using the following syntax:

```shell
terraform import aiven_flink_table.table project/service_name/table_id
```
