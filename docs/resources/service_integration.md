---
page_title: "aiven_service_integration Resource - terraform-provider-aiven"
subcategory: ""
description: |-
  The Service Integration resource allows the creation and management of Aiven Service Integrations.
---
# aiven_service_integration (Resource)
The Service Integration resource allows the creation and management of Aiven Service Integrations.

**Note** For services running on `hobbyist` plan service integrations are not supported.

Service Integration defines an integration between two Aiven services or between Aiven service and an external
integration endpoint. Integration could be for example sending metrics from Kafka service to an InfluxDB service,
getting metrics from an InfluxDB service to a Grafana service to show dashboards, sending logs from any service to
Elasticsearch, etc.

## Example Usage
```terraform
resource "aiven_service_integration" "my_integration_metrics" {
  project                  = aiven_project.myproject.project
  integration_type         = "metrics"
  source_service_name      = aiven_kafka.kfk1.service_name
  destination_service_name = aiven_m3db.m3db.service_name
}
```
<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `integration_type` (String) Type of the service integration. Possible values: `alertmanager`, `cassandra_cross_service_cluster`, `clickhouse_kafka`, `clickhouse_postgresql`, `dashboard`, `datadog`, `datasource`, `external_aws_cloudwatch_logs`, `external_aws_cloudwatch_metrics`, `external_elasticsearch_logs`, `external_google_cloud_logging`, `external_opensearch_logs`, `flink`, `internal_connectivity`, `jolokia`, `kafka_connect`, `kafka_logs`, `kafka_mirrormaker`, `logs`, `m3aggregator`, `m3coordinator`, `metrics`, `opensearch_cross_cluster_replication`, `opensearch_cross_cluster_search`, `prometheus`, `read_replica`, `rsyslog`, `schema_registry_proxy`
- `project` (String) Project the integration belongs to

### Optional

- `clickhouse_kafka_user_config` (Block Set) Integration user config (see [below for nested schema](#nestedblock--clickhouse_kafka_user_config))
- `clickhouse_postgresql_user_config` (Block Set) Integration user config (see [below for nested schema](#nestedblock--clickhouse_postgresql_user_config))
- `datadog_user_config` (Block Set) (see [below for nested schema](#nestedblock--datadog_user_config))
- `destination_endpoint_id` (String) Destination endpoint for the integration (if any)
- `destination_service_name` (String) Destination service for the integration (if any)
- `external_aws_cloudwatch_metrics_user_config` (Block Set) External AWS CloudWatch Metrics integration user config (see [below for nested schema](#nestedblock--external_aws_cloudwatch_metrics_user_config))
- `kafka_connect_user_config` (Block Set) Integration user config (see [below for nested schema](#nestedblock--kafka_connect_user_config))
- `kafka_logs_user_config` (Block Set) (see [below for nested schema](#nestedblock--kafka_logs_user_config))
- `kafka_mirrormaker_user_config` (Block Set) Integration user config (see [below for nested schema](#nestedblock--kafka_mirrormaker_user_config))
- `logs_user_config` (Block Set) (see [below for nested schema](#nestedblock--logs_user_config))
- `metrics_user_config` (Block Set) Integration user config (see [below for nested schema](#nestedblock--metrics_user_config))
- `source_endpoint_id` (String) Source endpoint for the integration (if any)
- `source_service_name` (String) Source service for the integration (if any)
- `timeouts` (Block, Optional) (see [below for nested schema](#nestedblock--timeouts))

### Read-Only

- `id` (String) The ID of this resource.
- `integration_id` (String) Service Integration Id at aiven

<a id="nestedblock--clickhouse_kafka_user_config"></a>
### Nested Schema for `clickhouse_kafka_user_config`

Optional:

- `tables` (Block Set) Tables to create (see [below for nested schema](#nestedblock--clickhouse_kafka_user_config--tables))

<a id="nestedblock--clickhouse_kafka_user_config--tables"></a>
### Nested Schema for `clickhouse_kafka_user_config.tables`

Required:

- `data_format` (String) Message data format. The default value is `JSONEachRow`.
- `group_name` (String) Kafka consumers group. The default value is `clickhouse`.
- `name` (String) Name of the table.

Optional:

- `auto_offset_reset` (String) Action to take when there is no initial offset in offset store or the desired offset is out of range. The default value is `earliest`.
- `columns` (Block Set) Table columns (see [below for nested schema](#nestedblock--clickhouse_kafka_user_config--tables--columns))
- `date_time_input_format` (String) Method to read DateTime from text input formats. The default value is `basic`.
- `handle_error_mode` (String) How to handle errors for Kafka engine. The default value is `default`.
- `max_block_size` (Number) Number of row collected by poll(s) for flushing data from Kafka. The default value is `0`.
- `max_rows_per_message` (Number) The maximum number of rows produced in one kafka message for row-based formats. The default value is `1`.
- `num_consumers` (Number) The number of consumers per table per replica. The default value is `1`.
- `poll_max_batch_size` (Number) Maximum amount of messages to be polled in a single Kafka poll. The default value is `0`.
- `skip_broken_messages` (Number) Skip at least this number of broken messages from Kafka topic per block. The default value is `0`.
- `topics` (Block Set) Kafka topics (see [below for nested schema](#nestedblock--clickhouse_kafka_user_config--tables--topics))

<a id="nestedblock--clickhouse_kafka_user_config--tables--columns"></a>
### Nested Schema for `clickhouse_kafka_user_config.tables.columns`

Required:

- `name` (String) Column name.
- `type` (String) Column type.


<a id="nestedblock--clickhouse_kafka_user_config--tables--topics"></a>
### Nested Schema for `clickhouse_kafka_user_config.tables.topics`

Required:

- `name` (String) Name of the topic.




<a id="nestedblock--clickhouse_postgresql_user_config"></a>
### Nested Schema for `clickhouse_postgresql_user_config`

Optional:

- `databases` (Block Set) Databases to expose (see [below for nested schema](#nestedblock--clickhouse_postgresql_user_config--databases))

<a id="nestedblock--clickhouse_postgresql_user_config--databases"></a>
### Nested Schema for `clickhouse_postgresql_user_config.databases`

Optional:

- `database` (String) PostgreSQL database to expose. The default value is `defaultdb`.
- `schema` (String) PostgreSQL schema to expose. The default value is `public`.



<a id="nestedblock--datadog_user_config"></a>
### Nested Schema for `datadog_user_config`

Optional:

- `datadog_dbm_enabled` (Boolean) Enable Datadog Database Monitoring.
- `datadog_tags` (Block Set) Custom tags provided by user (see [below for nested schema](#nestedblock--datadog_user_config--datadog_tags))
- `exclude_consumer_groups` (Set of String) List of custom metrics.
- `exclude_topics` (Set of String) List of topics to exclude.
- `include_consumer_groups` (Set of String) List of custom metrics.
- `include_topics` (Set of String) List of topics to include.
- `kafka_custom_metrics` (Set of String) List of custom metrics.
- `max_jmx_metrics` (Number) Maximum number of JMX metrics to send.
- `opensearch` (Block Set) Datadog Opensearch Options (see [below for nested schema](#nestedblock--datadog_user_config--opensearch))
- `redis` (Block Set) Datadog Redis Options (see [below for nested schema](#nestedblock--datadog_user_config--redis))

<a id="nestedblock--datadog_user_config--datadog_tags"></a>
### Nested Schema for `datadog_user_config.datadog_tags`

Required:

- `tag` (String) Tag format and usage are described here: https://docs.datadoghq.com/getting_started/tagging. Tags with prefix 'aiven-' are reserved for Aiven.

Optional:

- `comment` (String) Optional tag explanation.


<a id="nestedblock--datadog_user_config--opensearch"></a>
### Nested Schema for `datadog_user_config.opensearch`

Optional:

- `index_stats_enabled` (Boolean) Enable Datadog Opensearch Index Monitoring.
- `pending_task_stats_enabled` (Boolean) Enable Datadog Opensearch Pending Task Monitoring.
- `pshard_stats_enabled` (Boolean) Enable Datadog Opensearch Primary Shard Monitoring.


<a id="nestedblock--datadog_user_config--redis"></a>
### Nested Schema for `datadog_user_config.redis`

Optional:

- `command_stats_enabled` (Boolean) Enable command_stats option in the agent's configuration. The default value is `false`.



<a id="nestedblock--external_aws_cloudwatch_metrics_user_config"></a>
### Nested Schema for `external_aws_cloudwatch_metrics_user_config`

Optional:

- `dropped_metrics` (Block Set) Metrics to not send to AWS CloudWatch (takes precedence over extra_metrics) (see [below for nested schema](#nestedblock--external_aws_cloudwatch_metrics_user_config--dropped_metrics))
- `extra_metrics` (Block Set) Metrics to allow through to AWS CloudWatch (in addition to default metrics) (see [below for nested schema](#nestedblock--external_aws_cloudwatch_metrics_user_config--extra_metrics))

<a id="nestedblock--external_aws_cloudwatch_metrics_user_config--dropped_metrics"></a>
### Nested Schema for `external_aws_cloudwatch_metrics_user_config.dropped_metrics`

Required:

- `field` (String) Identifier of a value in the metric.
- `metric` (String) Identifier of the metric.


<a id="nestedblock--external_aws_cloudwatch_metrics_user_config--extra_metrics"></a>
### Nested Schema for `external_aws_cloudwatch_metrics_user_config.extra_metrics`

Required:

- `field` (String) Identifier of a value in the metric.
- `metric` (String) Identifier of the metric.



<a id="nestedblock--kafka_connect_user_config"></a>
### Nested Schema for `kafka_connect_user_config`

Optional:

- `kafka_connect` (Block Set) Kafka Connect service configuration values (see [below for nested schema](#nestedblock--kafka_connect_user_config--kafka_connect))

<a id="nestedblock--kafka_connect_user_config--kafka_connect"></a>
### Nested Schema for `kafka_connect_user_config.kafka_connect`

Optional:

- `config_storage_topic` (String) The name of the topic where connector and task configuration data are stored.This must be the same for all workers with the same group_id.
- `group_id` (String) A unique string that identifies the Connect cluster group this worker belongs to.
- `offset_storage_topic` (String) The name of the topic where connector and task configuration offsets are stored.This must be the same for all workers with the same group_id.
- `status_storage_topic` (String) The name of the topic where connector and task configuration status updates are stored.This must be the same for all workers with the same group_id.



<a id="nestedblock--kafka_logs_user_config"></a>
### Nested Schema for `kafka_logs_user_config`

Required:

- `kafka_topic` (String) Topic name.

Optional:

- `selected_log_fields` (Set of String) The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.


<a id="nestedblock--kafka_mirrormaker_user_config"></a>
### Nested Schema for `kafka_mirrormaker_user_config`

Optional:

- `cluster_alias` (String) The alias under which the Kafka cluster is known to MirrorMaker. Can contain the following symbols: ASCII alphanumerics, '.', '_', and '-'.
- `kafka_mirrormaker` (Block Set) Kafka MirrorMaker configuration values (see [below for nested schema](#nestedblock--kafka_mirrormaker_user_config--kafka_mirrormaker))

<a id="nestedblock--kafka_mirrormaker_user_config--kafka_mirrormaker"></a>
### Nested Schema for `kafka_mirrormaker_user_config.kafka_mirrormaker`

Optional:

- `consumer_fetch_min_bytes` (Number) The minimum amount of data the server should return for a fetch request.
- `producer_batch_size` (Number) The batch size in bytes producer will attempt to collect before publishing to broker.
- `producer_buffer_memory` (Number) The amount of bytes producer can use for buffering data before publishing to broker.
- `producer_compression_type` (String) Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.
- `producer_linger_ms` (Number) The linger time (ms) for waiting new data to arrive for publishing.
- `producer_max_request_size` (Number) The maximum request size in bytes.



<a id="nestedblock--logs_user_config"></a>
### Nested Schema for `logs_user_config`

Optional:

- `elasticsearch_index_days_max` (Number) Elasticsearch index retention limit. The default value is `3`.
- `elasticsearch_index_prefix` (String) Elasticsearch index prefix. The default value is `logs`.
- `selected_log_fields` (Set of String) The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.


<a id="nestedblock--metrics_user_config"></a>
### Nested Schema for `metrics_user_config`

Optional:

- `database` (String) Name of the database where to store metric datapoints. Only affects PostgreSQL destinations. Defaults to 'metrics'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.
- `retention_days` (Number) Number of days to keep old metrics. Only affects PostgreSQL destinations. Set to 0 for no automatic cleanup. Defaults to 30 days.
- `ro_username` (String) Name of a user that can be used to read metrics. This will be used for Grafana integration (if enabled) to prevent Grafana users from making undesired changes. Only affects PostgreSQL destinations. Defaults to 'metrics_reader'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.
- `source_mysql` (Block Set) Configuration options for metrics where source service is MySQL (see [below for nested schema](#nestedblock--metrics_user_config--source_mysql))
- `username` (String) Name of the user used to write metrics. Only affects PostgreSQL destinations. Defaults to 'metrics_writer'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.

<a id="nestedblock--metrics_user_config--source_mysql"></a>
### Nested Schema for `metrics_user_config.source_mysql`

Optional:

- `telegraf` (Block Set) Configuration options for Telegraf MySQL input plugin (see [below for nested schema](#nestedblock--metrics_user_config--source_mysql--telegraf))

<a id="nestedblock--metrics_user_config--source_mysql--telegraf"></a>
### Nested Schema for `metrics_user_config.source_mysql.telegraf`

Optional:

- `gather_event_waits` (Boolean) Gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS.
- `gather_file_events_stats` (Boolean) gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME.
- `gather_index_io_waits` (Boolean) Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE.
- `gather_info_schema_auto_inc` (Boolean) Gather auto_increment columns and max values from information schema.
- `gather_innodb_metrics` (Boolean) Gather metrics from INFORMATION_SCHEMA.INNODB_METRICS.
- `gather_perf_events_statements` (Boolean) Gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST.
- `gather_process_list` (Boolean) Gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST.
- `gather_slave_status` (Boolean) Gather metrics from SHOW SLAVE STATUS command output.
- `gather_table_io_waits` (Boolean) Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE.
- `gather_table_lock_waits` (Boolean) Gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS.
- `gather_table_schema` (Boolean) Gather metrics from INFORMATION_SCHEMA.TABLES.
- `perf_events_statements_digest_text_limit` (Number) Truncates digest text from perf_events_statements into this many characters.
- `perf_events_statements_limit` (Number) Limits metrics from perf_events_statements.
- `perf_events_statements_time_limit` (Number) Only include perf_events_statements whose last seen is less than this many seconds.




<a id="nestedblock--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
- `delete` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
- `read` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Read operations occur during any refresh or planning operation when refresh is enabled.
- `update` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
## Import
Import is supported using the following syntax:
```shell
terraform import aiven_service_integration.myintegration project/integration_id
```
